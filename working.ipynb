{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'OpenAI' from 'openai' (/home/pyare/anaconda3/envs/project/lib/python3.11/site-packages/openai/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/home/pyare/Desktop/BioPharma/project/Langchain Chatbot/working.ipynb Cell 1\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/pyare/Desktop/BioPharma/project/Langchain%20Chatbot/working.ipynb#W0sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mopenai\u001b[39;00m \u001b[39mimport\u001b[39;00m OpenAI\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/pyare/Desktop/BioPharma/project/Langchain%20Chatbot/working.ipynb#W0sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m client \u001b[39m=\u001b[39m OpenAI()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/pyare/Desktop/BioPharma/project/Langchain%20Chatbot/working.ipynb#W0sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m response \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39mchat\u001b[39m.\u001b[39mcompletions\u001b[39m.\u001b[39mcreate(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/pyare/Desktop/BioPharma/project/Langchain%20Chatbot/working.ipynb#W0sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m   model\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgpt-3.5-turbo-1106\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/pyare/Desktop/BioPharma/project/Langchain%20Chatbot/working.ipynb#W0sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m   response_format\u001b[39m=\u001b[39m{ \u001b[39m\"\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mjson_object\u001b[39m\u001b[39m\"\u001b[39m },\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/pyare/Desktop/BioPharma/project/Langchain%20Chatbot/working.ipynb#W0sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m   ]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/pyare/Desktop/BioPharma/project/Langchain%20Chatbot/working.ipynb#W0sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m )\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'OpenAI' from 'openai' (/home/pyare/anaconda3/envs/project/lib/python3.11/site-packages/openai/__init__.py)"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo-1106\",\n",
    "  response_format={ \"type\": \"json_object\" },\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant designed to output JSON.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"}\n",
    "  ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.chains.conversation.memory import ConversationBufferWindowMemory\n",
    "from langchain.prompts import (\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    ChatPromptTemplate,\n",
    "    MessagesPlaceholder\n",
    ")\n",
    "import streamlit as st\n",
    "from streamlit_chat import message\n",
    "from utils import *\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "\n",
    "st.subheader(\"Chatbot with Langchain, ChatGPT, Pinecone, and Streamlit\")\n",
    "\n",
    "if 'responses' not in st.session_state:\n",
    "    st.session_state['responses'] = [\"How can I assist you?\"]\n",
    "\n",
    "if 'requests' not in st.session_state:\n",
    "    st.session_state['requests'] = []\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", openai_api_key=\"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\")\n",
    "\n",
    "if 'buffer_memory' not in st.session_state:\n",
    "            st.session_state.buffer_memory=ConversationBufferWindowMemory(k=3,return_messages=True)\n",
    "\n",
    "\n",
    "system_msg_template = SystemMessagePromptTemplate.from_template(template=\"\"\"Answer the question as truthfully as possible using the provided context, \n",
    "and if the answer is not contained within the text below, say 'I don't know'\"\"\")\n",
    "\n",
    "\n",
    "human_msg_template = HumanMessagePromptTemplate.from_template(template=\"{input}\")\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages([system_msg_template, MessagesPlaceholder(variable_name=\"history\"), human_msg_template])\n",
    "\n",
    "# conversation = ConversationChain(memory=st.session_state.buffer_memory, prompt=prompt_template, llm=llm, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain.chat_models.openai.ChatOpenAI"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m     \n",
      "\u001b[0mllm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmessages\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'List[BaseMessage]'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mstop\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Optional[List[str]]'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Callbacks'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Any'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m'BaseMessage'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mType:\u001b[0m           ChatOpenAI\n",
      "\u001b[0;31mString form:\u001b[0m    client=<class 'openai.api_resources.chat_completion.ChatCompletion'> openai_api_key='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' openai_proxy=''\n",
      "\u001b[0;31mFile:\u001b[0m           ~/anaconda3/envs/project/lib/python3.11/site-packages/langchain/chat_models/openai.py\n",
      "\u001b[0;31mDocstring:\u001b[0m     \n",
      "`OpenAI` Chat large language models API.\n",
      "\n",
      "To use, you should have the ``openai`` python package installed, and the\n",
      "environment variable ``OPENAI_API_KEY`` set with your API key.\n",
      "\n",
      "Any parameters that are valid to be passed to the openai.create call can be passed\n",
      "in, even if not explicitly saved on this class.\n",
      "\n",
      "Example:\n",
      "    .. code-block:: python\n",
      "\n",
      "        from langchain.chat_models import ChatOpenAI\n",
      "        openai = ChatOpenAI(model_name=\"gpt-3.5-turbo\")\n",
      "\u001b[0;31mInit docstring:\u001b[0m\n",
      "Create a new model by parsing and validating input data from keyword arguments.\n",
      "\n",
      "Raises ValidationError if the input data cannot be parsed to form a valid model."
     ]
    }
   ],
   "source": [
    "llm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
